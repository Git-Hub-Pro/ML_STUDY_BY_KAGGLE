{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2018DatScienceBowl_UNET.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxGJyE2KCfT1zIXcalIU8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Git-Hub-Pro/ML_STUDY_BY_KAGGLE/blob/master/2018DatScienceBowl_UNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLwYkxpAorQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gim1ogAposB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os는 파일에 접근하게 해주는 라이브러리이다.\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "# 데이터 처리를 하는데 사용되는 라이브러리\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# plot chart 를 만들어주는 라이브러리.\n",
        "import matplotlib.pyplot as plt\n",
        "# skimage 라이브러리 image를 처리할 때, 사용하는 라이브러리\n",
        "from tqdm import tqdm # 상태바 기능을 제공, 완료 진행과정을 보여줍니다. \n",
        "from itertools import chain # chain 은 서로 다른 리스트를 묶어 준후, 순서대로 출력하는 기능을 제공해줍니다.\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "# keras로 Machine Learnin 관련된 언어로, ML 모델을 만들 때, 필요한 라이브러리를 제공합니다.  \n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dropout,Lambda # Dropout은 overfitting을 막기위하여 사용되고 있다.\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D # MaxPooling2D는 이미지 사이즈를 축소하는데 사용되고 있다.\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "# Set some parameters\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 3\n",
        "# colab을 사용하고 있어서 아래와 같은 경로를 사용하였습니다.../content/gdrive/My Drive/까지는 기본적으로 클라우드 실행시 경로입니다. \n",
        "TRAIN_PATH = '../content/gdrive/My Drive/data/kaggle_data/stage1_train/'\n",
        "TEST_PATH  = '../content/gdrive/My Drive/data/kaggle_data/stage1_test/'\n",
        "\n",
        "warnings.filterwarnings('ignore',category=UserWarning,module='skimage')\n",
        "seed = 42\n",
        "random.seed = seed\n",
        "np.random.seed = seed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPUqpZMDtjXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get train and test IDs (image 폴더가 들어간 디렉토리 이름 리스트 저장)\n",
        "# [0] : directory path (PWD) [1] : all sub-directories [2] : all sub-files\n",
        "# [0] : 특정 디렉토리의 위치값을 저장 [1] : 특정 디렉토리의 하위 디렉토리 리스트를 저장 [2]: 특정 디렉토리에 포함된 모든 파일 리스트를 저장\n",
        "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
        "test_ids = next(os.walk(TEST_PATH))[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIErUczjoeWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get and resize train images and masks \n",
        "# Get and resize train images and masks\n",
        "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "print('Getting and resizing train images and masks ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "    path = TRAIN_PATH + id_\n",
        "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_train[n] = img\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "        mask_ = imread(path + '/masks/' + mask_file)\n",
        "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
        "                                      preserve_range=True), axis=-1)\n",
        "        mask = np.maximum(mask, mask_)  # 모든 마스크를 다 더하기.\n",
        "    Y_train[n] = mask\n",
        "\n",
        "# Get and resize test images\n",
        "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "sizes_test = []\n",
        "print('Getting and resizing test images ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "    path = TEST_PATH + id_\n",
        "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "    sizes_test.append([img.shape[0], img.shape[1]])\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_test[n] = img\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1NNpmYKysEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if training data looks all right\n",
        "ix = random.randint(0,len(train_ids))\n",
        "imshow(X_train[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[ix]))\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbEjmaJRvjgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define IoU metric\n",
        "# IoU 매트릭은 target과 prediction 사이의 공통 픽셀 수를 총 픽셀 수로 나눈 값을 측정합니다.\n",
        "# Mean IU :(전체 픽셀과 예측 실패 픽셀-예측성공 픽셀의 합에서 예측 성공 픽셀 합=IOU)의 평균\n",
        "# 아래 식은 픽셀의 예측이 0.5 ~ 1.0 사이의 값들을 IOU의 평균값을 구하는 식입니다.\n",
        "# Define IoU metric\n",
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return K.mean(K.stack(prec), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCNuM8zSDa6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build U-Net Model(c1~c5까지는 이미지의 크기가 점점 작아지고, u6~c9까지는 이미지의 크기를 키워준다.이때 이전의 weight값을 서로 연결시켜줘서 보정을 해준다.))\n",
        "# 모델링이 되어지면 이미지마다 그 점마다 맞았다는 확률로 변환이 가능하다. 많은 트레이닝 케이스로 모델링을 할 수있다.\n",
        "# U-Net의 특징은 적은 케이스로 모델링을 할 수 있는 장점이 있다.\n",
        "# Build U-Net model\n",
        "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
        "c1 = Dropout(0.1) (c1)\n",
        "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "c2 = Dropout(0.1) (c2)\n",
        "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "c3 = Dropout(0.2) (c3)\n",
        "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "c4 = Dropout(0.2) (c4)\n",
        "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "c5 = Dropout(0.3) (c5)\n",
        "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "u6 = concatenate([u6, c4])\n",
        "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "c6 = Dropout(0.2) (c6)\n",
        "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "u7 = concatenate([u7, c3])\n",
        "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "c7 = Dropout(0.2) (c7)\n",
        "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "u8 = concatenate([u8, c2])\n",
        "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "c8 = Dropout(0.1) (c8)\n",
        "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "u9 = concatenate([u9, c1], axis=3)\n",
        "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "c9 = Dropout(0.1) (c9)\n",
        "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
        "model.summary()\n",
        "                                                      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5C6Zi1xlJhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit model1\n",
        "earlystopper = EarlyStopping(patience=5,verbose=1)\n",
        "checkpointer = ModelCheckpoint('/content/gdrive/My Drive/data/kaggle_data/model-dsbow2018-1.h5',verbose=1,save_best_only=True)\n",
        "results = model.fit(X_train,Y_train,validation_split=0.1,batch_size=16,epochs=50,callbacks=[earlystopper,checkpointer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdn4N0KGlr5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMQhVqonly-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict on train, val and test\n",
        "model = load_model('/content/gdrive/My Drive/data/kaggle_data/model-dsbow2018-1.h5',custom_objects={'mean_iou':mean_iou})\n",
        "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)],verbose=1)\n",
        "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "# Threshold predictions\n",
        "preds_train_t = (preds_train>0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val>0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test>0.5).astype(np.uint8)\n",
        "\n",
        "# Create list of upsampled test masks\n",
        "preds_test_upsampled = []\n",
        "for i in range(len(preds_test)):\n",
        "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
        "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
        "                                       mode='constant', preserve_range=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9dSBbH_noM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform a sanity check on some random training samples\n",
        "ix = random.randint(0, len(preds_train_t))\n",
        "imshow(X_train[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_train_t[ix]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIZinAven-PX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform a sanity check on some random validation samples\n",
        "ix = random.randint(0, len(preds_val_t))\n",
        "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_val_t[ix]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em0go6maovrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
        "def rle_encoding(x):\n",
        "    dots = np.where(x.T.flatten() == 1)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths\n",
        "\n",
        "def prob_to_rles(x, cutoff=0.5):\n",
        "    lab_img = label(x > cutoff)\n",
        "    for i in range(1, lab_img.max() + 1):\n",
        "        yield rle_encoding(lab_img == i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kVQUqf3oxgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_test_ids = []\n",
        "rles = []\n",
        "for n, id_ in enumerate(test_ids):\n",
        "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
        "    rles.extend(rle)\n",
        "    new_test_ids.extend([id_]*len(rle))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdYDRFIUpDlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create submission DataFrame\n",
        "sub = pd.DataFrame()\n",
        "sub['ImageId'] = new_test_ids\n",
        "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
        "sub.to_csv('/content/gdrive/My Drive/data/kaggle_data/sub-dsbowl12018-1.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}