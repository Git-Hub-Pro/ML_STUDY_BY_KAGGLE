{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo_v3_ObjectDetection_in_Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTuByEFF9uqGgUkzdlwiNC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Git-Hub-Pro/ML_STUDY_BY_KAGGLE/blob/master/Yolo_v3_ObjectDetection_in_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_v7N8YkBtCp",
        "colab_type": "text"
      },
      "source": [
        "# 1.What is Yolo?\n",
        "Yolo (you only look once)로 한번에 물체의 위치를 파악하고, 물체까지 분류하는 알고리즘이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzC5ssMXchoJ",
        "colab_type": "text"
      },
      "source": [
        "# YOLOv3 Architecture\n",
        "Feature pyramid network 구조와 비슷하며 scale 3개는 3구간으로 이미지를 나누었을때,\n",
        "첫번째 구간은 큰 이미지를 찾고, 두번째 구간에서 중간 사이즈 이미지를 찾고, 세번째 구간에서는 큰 이미지를 찾는 식으로 진행합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIjwhH05WKee",
        "colab_type": "text"
      },
      "source": [
        "출처  : https://www.kaggle.com/aruchomu/yolo-v3-object-detection-in-tensorflow\n",
        "\n",
        "데이터: https://github.com/heartkilla/yolo-v3\n",
        "\n",
        "관련 이론 강의 : https://www.youtube.com/watch?v=HMgcvgRrDcA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMErnpOwCNZb",
        "colab_type": "code",
        "outputId": "6ed696cf-fea1-4dd1-bc30-a34a2dca4853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovewdEHMCJMp",
        "colab_type": "text"
      },
      "source": [
        "#2. Dependencies(필요한 라이브러리)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVwwm8rhCBAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf # 머신러닝 라이브러리(모델 생성 및 사용)\n",
        "import numpy as np  # 행렬 및 데이터 처리 라이브러리\n",
        "from PIL import Image, ImageDraw, ImageFont # 이미지 파일 불러오기 및 이미지 생성\n",
        "from IPython.display import display\n",
        "from seaborn import color_palette #데이터 시각화 라이브러리 참고 : https://github.com/Git-Hub-Pro/Data-visualization\n",
        "import cv2  # OpenCV 라이브러리\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "tf.reset_default_graph() # 지금까지 생성된 모든 텐서를 그래프에서 제거"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsQV7sCmEL3D",
        "colab_type": "text"
      },
      "source": [
        "#3. Model hyperparameters(모델 파라미터)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYI-yo-cESEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# configurations for Yolo\n",
        "_BATCH_NORM_DECAY = 0.9\n",
        "_BATCH_NORM_EPSILON = 1e-05\n",
        "_LEAKY_RELU = 0.1\n",
        "# COCO dataset the 9 clusters \n",
        "_ANCHORS = [(10, 13), (16, 30), (33, 23),      # 작은 물체를 찾을 때 사용.\n",
        "            (30, 61), (62, 45), (59, 119),     # 중간 물체를 찾을 때 사용.\n",
        "            (116, 90), (156, 198), (373, 326)] # 큰 물체를 찾을 때 사용.\n",
        "_MODEL_SIZE = (416, 416) # input size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjUG5icXFbKz",
        "colab_type": "text"
      },
      "source": [
        "# Batch normalization\n",
        "Yolo에 있는 모든 convolutional layer에 사용되는 Batch normalization입니다.\n",
        "모델이 학습하는데 빠르고, 변수들의 수를 줄이는데 효과가 좋습니다.\n",
        "(이미지에서 작은 이미지를 잘 인식할 수 있도록 도와줍니다.)\n",
        "_BATCH_NORM_EPSILON : 엡실론 관련 함수\n",
        "_BATCH_NORM_DECAY : 모멘텀, 이동 평균 및 변수를 계산해줍니다. forward propagation 에 사용됩니다.\n",
        "moving_average = momentum * moving_average + (1-momentum)*current_average"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otorg-P0HiVn",
        "colab_type": "text"
      },
      "source": [
        "# Leaky Relu\n",
        "활성화 함수로 은닉층이 증가할수록 학습이 떨어지는 것을 막아줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgR5UcweHxtn",
        "colab_type": "text"
      },
      "source": [
        "#Anchors\n",
        "COCO란 많은 물체 인식 데이터 셋입니다. 이 COCO를 바탕으로 k-means clustering을 진행하여 만든 것이 Anchors입니다.이때, bounding box(경계 상자, 물체 인식을 해주는 부분)형태로 정렬되어있습니다. bounging box를 바탕으로 sigmoid 함수로 물체를 예측합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f-pFAd8JRW0",
        "colab_type": "text"
      },
      "source": [
        "# 4. Model definiton\n",
        "batch_norm 함수를 만들어 사용하면 ResNet 과 Yolo 구조를 사용할 때, 편리하게 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9Xc9GPdHX2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_norm(inputs, training, data_format):\n",
        "    \"\"\"Performs a batch normalization using a standard set of parameters.\"\"\"\n",
        "    return tf.layers.batch_normalization(\n",
        "        inputs=inputs, axis=1 if data_format == 'channels_first' else 3,\n",
        "        momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON,\n",
        "        scale=True, training=training)\n",
        "\n",
        "\n",
        "def fixed_padding(inputs, kernel_size, data_format):\n",
        "    \"\"\"ResNet implementation of fixed padding.\n",
        "\n",
        "    Pads the input along the spatial dimensions independently of input size.\n",
        "\n",
        "    Args:\n",
        "        inputs: Tensor input to be padded.\n",
        "        kernel_size: The kernel to be used in the conv2d or max_pool2d.\n",
        "        data_format: The input format.\n",
        "    Returns:\n",
        "        A tensor with the same format as the input.\n",
        "    \"\"\"\n",
        "    pad_total = kernel_size - 1\n",
        "    pad_beg = pad_total // 2\n",
        "    pad_end = pad_total - pad_beg\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n",
        "                                        [pad_beg, pad_end],\n",
        "                                        [pad_beg, pad_end]])\n",
        "    else:\n",
        "        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
        "                                        [pad_beg, pad_end], [0, 0]])\n",
        "    return padded_inputs\n",
        "\n",
        "\n",
        "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
        "    \"\"\"Strided 2-D convolution with explicit padding.\"\"\"\n",
        "    if strides > 1:\n",
        "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
        "\n",
        "    return tf.layers.conv2d(\n",
        "        inputs=inputs, filters=filters, kernel_size=kernel_size,\n",
        "        strides=strides, padding=('SAME' if strides == 1 else 'VALID'),\n",
        "        use_bias=False, data_format=data_format)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKBFq7_4XeF2",
        "colab_type": "text"
      },
      "source": [
        "# Feature extraction : Darknet-53\n",
        "Yolo는 Image Net으로 trained 되어진 Darknet-53을 사용합니다.\n",
        "Darknet의 성능은 \n",
        "Bn Ops : 18.7(단위 10억), FPS : 78 , BFLOP/s : 1457\n",
        "실시간 속도는 v2보다는 적었지만, GPU 연산량 활용이 높아졌습니다. \n",
        "(참고로 layer가 많아질수록 속도가 느려집니다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owYe6vmMXY-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def darknet53_residual_block(inputs, filters, training, data_format,\n",
        "                             strides=1):\n",
        "    \"\"\"Creates a residual block for Darknet.\"\"\"\n",
        "    shortcut = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(\n",
        "        inputs, filters=filters, kernel_size=1, strides=strides,\n",
        "        data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(\n",
        "        inputs, filters=2 * filters, kernel_size=3, strides=strides,\n",
        "        data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs += shortcut\n",
        "\n",
        "    return inputs\n",
        "\n",
        "\n",
        "def darknet53(inputs, training, data_format):\n",
        "    \"\"\"Creates Darknet53 model for feature extraction.\"\"\"\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = darknet53_residual_block(inputs, filters=32, training=training,\n",
        "                                      data_format=data_format)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=128, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(2):\n",
        "        inputs = darknet53_residual_block(inputs, filters=64,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(8):\n",
        "        inputs = darknet53_residual_block(inputs, filters=128,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    route1 = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(8):\n",
        "        inputs = darknet53_residual_block(inputs, filters=256,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    route2 = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3,\n",
        "                                  strides=2, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(4):\n",
        "        inputs = darknet53_residual_block(inputs, filters=512,\n",
        "                                          training=training,\n",
        "                                          data_format=data_format)\n",
        "\n",
        "    return route1, route2, inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfZptb4m3Bkc",
        "colab_type": "text"
      },
      "source": [
        "# Convolution layers \n",
        "Yolo는 무수히 많은 컨벌루션 레이어를 가지고 있고, 아래와 같은 방법으로 블록화하면 유용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6gq3cT52_F8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yolo_convolution_block(inputs, filters, training, data_format):\n",
        "    \"\"\"Creates convolution operations layer used after Darknet.\"\"\"\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    route = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    return route, inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBTq-fvA6LIJ",
        "colab_type": "text"
      },
      "source": [
        "# Detection layers\n",
        "yolo 는 3개의 detection 층이 있습니다. 3개의 서로 다른 scale를 사용합니다.\n",
        "coco data set을 활용한 anchor는 n_anchors *(5 + n_classes) 1x1 convolution을 사용합니다. 그리고 물체의 사각형 좌표와 그 물체에 대한 확률에 대해서 예측할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QqMSqj05iOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yolo_layer(inputs, n_classes, anchors, img_size, data_format):\n",
        "    \"\"\"Creates Yolo final detection layer.\n",
        "\n",
        "    Detects boxes with respect to anchors.\n",
        "\n",
        "    Args:\n",
        "        inputs: Tensor input.\n",
        "        n_classes: Number of labels.\n",
        "        anchors: A list of anchor sizes.\n",
        "        img_size: The input size of the model.\n",
        "        data_format: The input format.\n",
        "\n",
        "    Returns:\n",
        "        Tensor output.\n",
        "    \"\"\"\n",
        "    n_anchors = len(anchors)\n",
        "\n",
        "    inputs = tf.layers.conv2d(inputs, filters=n_anchors * (5 + n_classes),\n",
        "                              kernel_size=1, strides=1, use_bias=True,\n",
        "                              data_format=data_format)\n",
        "\n",
        "    shape = inputs.get_shape().as_list()\n",
        "    grid_shape = shape[2:4] if data_format == 'channels_first' else shape[1:3]\n",
        "    if data_format == 'channels_first':\n",
        "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
        "    inputs = tf.reshape(inputs, [-1, n_anchors * grid_shape[0] * grid_shape[1],\n",
        "                                 5 + n_classes])\n",
        "\n",
        "    strides = (img_size[0] // grid_shape[0], img_size[1] // grid_shape[1])\n",
        "\n",
        "    box_centers, box_shapes, confidence, classes = \\\n",
        "        tf.split(inputs, [2, 2, 1, n_classes], axis=-1)\n",
        "\n",
        "    x = tf.range(grid_shape[0], dtype=tf.float32)\n",
        "    y = tf.range(grid_shape[1], dtype=tf.float32)\n",
        "    x_offset, y_offset = tf.meshgrid(x, y)\n",
        "    x_offset = tf.reshape(x_offset, (-1, 1))\n",
        "    y_offset = tf.reshape(y_offset, (-1, 1))\n",
        "    x_y_offset = tf.concat([x_offset, y_offset], axis=-1)\n",
        "    x_y_offset = tf.tile(x_y_offset, [1, n_anchors])\n",
        "    x_y_offset = tf.reshape(x_y_offset, [1, -1, 2])\n",
        "    box_centers = tf.nn.sigmoid(box_centers)\n",
        "    box_centers = (box_centers + x_y_offset) * strides\n",
        "\n",
        "    anchors = tf.tile(anchors, [grid_shape[0] * grid_shape[1], 1])\n",
        "    box_shapes = tf.exp(box_shapes) * tf.to_float(anchors)\n",
        "\n",
        "    confidence = tf.nn.sigmoid(confidence)\n",
        "\n",
        "    classes = tf.nn.sigmoid(classes)\n",
        "\n",
        "    inputs = tf.concat([box_centers, box_shapes,\n",
        "                        confidence, classes], axis=-1)\n",
        "\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yky-nvly9Q6D",
        "colab_type": "text"
      },
      "source": [
        "# Upsample layer\n",
        "Darknet-53 에 나온 값을 detection 영역 input에 맞게 조절하기 위해 사용되어진다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdY-zCY99EJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upsample(inputs, out_shape, data_format):\n",
        "    \"\"\"Upsamples to `out_shape` using nearest neighbor interpolation.\"\"\"\n",
        "    if data_format == 'channels_first':\n",
        "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
        "        new_height = out_shape[3]\n",
        "        new_width = out_shape[2]\n",
        "    else:\n",
        "        new_height = out_shape[2]\n",
        "        new_width = out_shape[1]\n",
        "\n",
        "    inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
        "\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V95w4p8y925C",
        "colab_type": "text"
      },
      "source": [
        "# Non-mas suppression\n",
        "무수히 많은 박스 중에서 예측 신뢰도가 낮은 부분을 삭제한다. 그리고 물체안에 여러\n",
        "박스가 생기는 것을 막기 위해 사용되어 집니다. hard negative mining 방법을 사용하지 않고 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJwJqROj9ttk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_boxes(inputs):\n",
        "    \"\"\"Computes top left and bottom right points of the boxes.\"\"\"\n",
        "    center_x, center_y, width, height, confidence, classes = \\\n",
        "        tf.split(inputs, [1, 1, 1, 1, 1, -1], axis=-1)\n",
        "\n",
        "    top_left_x = center_x - width / 2\n",
        "    top_left_y = center_y - height / 2\n",
        "    bottom_right_x = center_x + width / 2\n",
        "    bottom_right_y = center_y + height / 2\n",
        "\n",
        "    boxes = tf.concat([top_left_x, top_left_y,\n",
        "                       bottom_right_x, bottom_right_y,\n",
        "                       confidence, classes], axis=-1)\n",
        "\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def non_max_suppression(inputs, n_classes, max_output_size, iou_threshold,\n",
        "                        confidence_threshold):\n",
        "    \"\"\"Performs non-max suppression separately for each class.\n",
        "\n",
        "    Args:\n",
        "        inputs: Tensor input.\n",
        "        n_classes: Number of classes.\n",
        "        max_output_size: Max number of boxes to be selected for each class.\n",
        "        iou_threshold: Threshold for the IOU.\n",
        "        confidence_threshold: Threshold for the confidence score.\n",
        "    Returns:\n",
        "        A list containing class-to-boxes dictionaries\n",
        "            for each sample in the batch.\n",
        "    \"\"\"\n",
        "    batch = tf.unstack(inputs)\n",
        "    boxes_dicts = []\n",
        "    for boxes in batch:\n",
        "        boxes = tf.boolean_mask(boxes, boxes[:, 4] > confidence_threshold)\n",
        "        classes = tf.argmax(boxes[:, 5:], axis=-1)\n",
        "        classes = tf.expand_dims(tf.to_float(classes), axis=-1)\n",
        "        boxes = tf.concat([boxes[:, :5], classes], axis=-1)\n",
        "\n",
        "        boxes_dict = dict()\n",
        "        for cls in range(n_classes):\n",
        "            mask = tf.equal(boxes[:, 5], cls)\n",
        "            mask_shape = mask.get_shape()\n",
        "            if mask_shape.ndims != 0:\n",
        "                class_boxes = tf.boolean_mask(boxes, mask)\n",
        "                boxes_coords, boxes_conf_scores, _ = tf.split(class_boxes,\n",
        "                                                              [4, 1, -1],\n",
        "                                                              axis=-1)\n",
        "                boxes_conf_scores = tf.reshape(boxes_conf_scores, [-1])\n",
        "                indices = tf.image.non_max_suppression(boxes_coords,\n",
        "                                                       boxes_conf_scores,\n",
        "                                                       max_output_size,\n",
        "                                                       iou_threshold)\n",
        "                class_boxes = tf.gather(class_boxes, indices)\n",
        "                boxes_dict[cls] = class_boxes[:, :5]\n",
        "\n",
        "        boxes_dicts.append(boxes_dict)\n",
        "\n",
        "    return boxes_dicts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOkqJhmV_koX",
        "colab_type": "text"
      },
      "source": [
        "# 5. Final Model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HvSPdo0_W0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Yolo_v3:\n",
        "    \"\"\"Yolo v3 model class.\"\"\"\n",
        "\n",
        "    def __init__(self, n_classes, model_size, max_output_size, iou_threshold,\n",
        "                 confidence_threshold, data_format=None):\n",
        "        \"\"\"Creates the model.\n",
        "\n",
        "        Args:\n",
        "            n_classes: Number of class labels.\n",
        "            model_size: The input size of the model.\n",
        "            max_output_size: Max number of boxes to be selected for each class.\n",
        "            iou_threshold: Threshold for the IOU.\n",
        "            confidence_threshold: Threshold for the confidence score.\n",
        "            data_format: The input format.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "        if not data_format:\n",
        "            if tf.test.is_built_with_cuda():\n",
        "                data_format = 'channels_first'\n",
        "            else:\n",
        "                data_format = 'channels_last'\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.model_size = model_size\n",
        "        self.max_output_size = max_output_size\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.confidence_threshold = confidence_threshold\n",
        "        self.data_format = data_format\n",
        "\n",
        "    def __call__(self, inputs, training):\n",
        "        \"\"\"Add operations to detect boxes for a batch of input images.\n",
        "\n",
        "        Args:\n",
        "            inputs: A Tensor representing a batch of input images.\n",
        "            training: A boolean, whether to use in training or inference mode.\n",
        "\n",
        "        Returns:\n",
        "            A list containing class-to-boxes dictionaries\n",
        "                for each sample in the batch.\n",
        "        \"\"\"\n",
        "        with tf.variable_scope('yolo_v3_model'):\n",
        "            if self.data_format == 'channels_first':\n",
        "                inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
        "\n",
        "            inputs = inputs / 255\n",
        "\n",
        "            route1, route2, inputs = darknet53(inputs, training=training,\n",
        "                                               data_format=self.data_format)\n",
        "\n",
        "            route, inputs = yolo_convolution_block(\n",
        "                inputs, filters=512, training=training,\n",
        "                data_format=self.data_format)\n",
        "            detect1 = yolo_layer(inputs, n_classes=self.n_classes,\n",
        "                                 anchors=_ANCHORS[6:9],\n",
        "                                 img_size=self.model_size,\n",
        "                                 data_format=self.data_format)\n",
        "\n",
        "            inputs = conv2d_fixed_padding(route, filters=256, kernel_size=1,\n",
        "                                          data_format=self.data_format)\n",
        "            inputs = batch_norm(inputs, training=training,\n",
        "                                data_format=self.data_format)\n",
        "            inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "            upsample_size = route2.get_shape().as_list()\n",
        "            inputs = upsample(inputs, out_shape=upsample_size,\n",
        "                              data_format=self.data_format)\n",
        "            axis = 1 if self.data_format == 'channels_first' else 3\n",
        "            inputs = tf.concat([inputs, route2], axis=axis)\n",
        "            route, inputs = yolo_convolution_block(\n",
        "                inputs, filters=256, training=training,\n",
        "                data_format=self.data_format)\n",
        "            detect2 = yolo_layer(inputs, n_classes=self.n_classes,\n",
        "                                 anchors=_ANCHORS[3:6],\n",
        "                                 img_size=self.model_size,\n",
        "                                 data_format=self.data_format)\n",
        "\n",
        "            inputs = conv2d_fixed_padding(route, filters=128, kernel_size=1,\n",
        "                                          data_format=self.data_format)\n",
        "            inputs = batch_norm(inputs, training=training,\n",
        "                                data_format=self.data_format)\n",
        "            inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "            upsample_size = route1.get_shape().as_list()\n",
        "            inputs = upsample(inputs, out_shape=upsample_size,\n",
        "                              data_format=self.data_format)\n",
        "            inputs = tf.concat([inputs, route1], axis=axis)\n",
        "            route, inputs = yolo_convolution_block(\n",
        "                inputs, filters=128, training=training,\n",
        "                data_format=self.data_format)\n",
        "            detect3 = yolo_layer(inputs, n_classes=self.n_classes,\n",
        "                                 anchors=_ANCHORS[0:3],\n",
        "                                 img_size=self.model_size,\n",
        "                                 data_format=self.data_format)\n",
        "\n",
        "            inputs = tf.concat([detect1, detect2, detect3], axis=1)\n",
        "\n",
        "            inputs = build_boxes(inputs)\n",
        "\n",
        "            boxes_dicts = non_max_suppression(\n",
        "                inputs, n_classes=self.n_classes,\n",
        "                max_output_size=self.max_output_size,\n",
        "                iou_threshold=self.iou_threshold,\n",
        "                confidence_threshold=self.confidence_threshold)\n",
        "\n",
        "            return boxes_dicts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H12rnYPf_1tg",
        "colab_type": "text"
      },
      "source": [
        "# 6. Utility 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXJ3yTqORPNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_images(img_names, model_size):\n",
        "    \"\"\"Loads images in a 4D array.\n",
        "\n",
        "    Args:\n",
        "        img_names: A list of images names.\n",
        "        model_size: The input size of the model.\n",
        "        data_format: A format for the array returned\n",
        "            ('channels_first' or 'channels_last').\n",
        "\n",
        "    Returns:\n",
        "        A 4D NumPy array.\n",
        "    \"\"\"\n",
        "    imgs = []\n",
        "\n",
        "    for img_name in img_names:\n",
        "        img = Image.open(img_name)\n",
        "        img = img.resize(size=model_size)\n",
        "        img = np.array(img, dtype=np.float32)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        imgs.append(img)\n",
        "\n",
        "    imgs = np.concatenate(imgs)\n",
        "\n",
        "    return imgs\n",
        "\n",
        "\n",
        "def load_class_names(file_name):\n",
        "    \"\"\"Returns a list of class names read from `file_name`.\"\"\"\n",
        "    with open(file_name, 'r') as f:\n",
        "        class_names = f.read().splitlines()\n",
        "    return class_names\n",
        "\n",
        "\n",
        "def draw_boxes(img_names, boxes_dicts, class_names, model_size):\n",
        "    \"\"\"Draws detected boxes.\n",
        "\n",
        "    Args:\n",
        "        img_names: A list of input images names.\n",
        "        boxes_dict: A class-to-boxes dictionary.\n",
        "        class_names: A class names list.\n",
        "        model_size: The input size of the model.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    colors = ((np.array(color_palette(\"hls\", 80)) * 255)).astype(np.uint8)\n",
        "    for num, img_name, boxes_dict in zip(range(len(img_names)), img_names,\n",
        "                                         boxes_dicts):\n",
        "        img = Image.open(img_name)\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        font = ImageFont.truetype(font='/content/gdrive/My Drive/data/yolo_v3/fonts/futur.ttf',\n",
        "                                  size=(img.size[0] + img.size[1]) // 100)\n",
        "        resize_factor = \\\n",
        "            (img.size[0] / model_size[0], img.size[1] / model_size[1])\n",
        "        for cls in range(len(class_names)):\n",
        "            boxes = boxes_dict[cls]\n",
        "            if np.size(boxes) != 0:\n",
        "                color = colors[cls]\n",
        "                for box in boxes:\n",
        "                    xy, confidence = box[:4], box[4]\n",
        "                    xy = [xy[i] * resize_factor[i % 2] for i in range(4)]\n",
        "                    x0, y0 = xy[0], xy[1]\n",
        "                    thickness = (img.size[0] + img.size[1]) // 200\n",
        "                    for t in np.linspace(0, 1, thickness):\n",
        "                        xy[0], xy[1] = xy[0] + t, xy[1] + t\n",
        "                        xy[2], xy[3] = xy[2] - t, xy[3] - t\n",
        "                        draw.rectangle(xy, outline=tuple(color))\n",
        "                    text = '{} {:.1f}%'.format(class_names[cls],\n",
        "                                               confidence * 100)\n",
        "                    text_size = draw.textsize(text, font=font)\n",
        "                    draw.rectangle(\n",
        "                        [x0, y0 - text_size[1], x0 + text_size[0], y0],\n",
        "                        fill=tuple(color))\n",
        "                    draw.text((x0, y0 - text_size[1]), text, fill='black',\n",
        "                              font=font)\n",
        "\n",
        "        display(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDs-WQ-vAIM4",
        "colab_type": "text"
      },
      "source": [
        "# 7. Converting weights to Tensorflow format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEwmSku6ACTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_weights(variables, file_name):\n",
        "    \"\"\"Reshapes and loads official pretrained Yolo weights.\n",
        "\n",
        "    Args:\n",
        "        variables: A list of tf.Variable to be assigned.\n",
        "        file_name: A name of a file containing weights.\n",
        "\n",
        "    Returns:\n",
        "        A list of assign operations.\n",
        "    \"\"\"\n",
        "    with open(file_name, \"rb\") as f:\n",
        "        # Skip first 5 values containing irrelevant info\n",
        "        np.fromfile(f, dtype=np.int32, count=5)\n",
        "        weights = np.fromfile(f, dtype=np.float32)\n",
        "\n",
        "        assign_ops = []\n",
        "        ptr = 0\n",
        "\n",
        "        # Load weights for Darknet part.\n",
        "        # Each convolution layer has batch normalization.\n",
        "        for i in range(52):\n",
        "            conv_var = variables[5 * i]\n",
        "            gamma, beta, mean, variance = variables[5 * i + 1:5 * i + 5]\n",
        "            batch_norm_vars = [beta, gamma, mean, variance]\n",
        "\n",
        "            for var in batch_norm_vars:\n",
        "                shape = var.shape.as_list()\n",
        "                num_params = np.prod(shape)\n",
        "                var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
        "                ptr += num_params\n",
        "                assign_ops.append(tf.assign(var, var_weights))\n",
        "\n",
        "            shape = conv_var.shape.as_list()\n",
        "            num_params = np.prod(shape)\n",
        "            var_weights = weights[ptr:ptr + num_params].reshape(\n",
        "                (shape[3], shape[2], shape[0], shape[1]))\n",
        "            var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
        "            ptr += num_params\n",
        "            assign_ops.append(tf.assign(conv_var, var_weights))\n",
        "\n",
        "        # Loading weights for Yolo part.\n",
        "        # 7th, 15th and 23rd convolution layer has biases and no batch norm.\n",
        "        ranges = [range(0, 6), range(6, 13), range(13, 20)]\n",
        "        unnormalized = [6, 13, 20]\n",
        "        for j in range(3):\n",
        "            for i in ranges[j]:\n",
        "                current = 52 * 5 + 5 * i + j * 2\n",
        "                conv_var = variables[current]\n",
        "                gamma, beta, mean, variance =  \\\n",
        "                    variables[current + 1:current + 5]\n",
        "                batch_norm_vars = [beta, gamma, mean, variance]\n",
        "\n",
        "                for var in batch_norm_vars:\n",
        "                    shape = var.shape.as_list()\n",
        "                    num_params = np.prod(shape)\n",
        "                    var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
        "                    ptr += num_params\n",
        "                    assign_ops.append(tf.assign(var, var_weights))\n",
        "\n",
        "                shape = conv_var.shape.as_list()\n",
        "                num_params = np.prod(shape)\n",
        "                var_weights = weights[ptr:ptr + num_params].reshape(\n",
        "                    (shape[3], shape[2], shape[0], shape[1]))\n",
        "                var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
        "                ptr += num_params\n",
        "                assign_ops.append(tf.assign(conv_var, var_weights))\n",
        "\n",
        "            bias = variables[52 * 5 + unnormalized[j] * 5 + j * 2 + 1]\n",
        "            shape = bias.shape.as_list()\n",
        "            num_params = np.prod(shape)\n",
        "            var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
        "            ptr += num_params\n",
        "            assign_ops.append(tf.assign(bias, var_weights))\n",
        "\n",
        "            conv_var = variables[52 * 5 + unnormalized[j] * 5 + j * 2]\n",
        "            shape = conv_var.shape.as_list()\n",
        "            num_params = np.prod(shape)\n",
        "            var_weights = weights[ptr:ptr + num_params].reshape(\n",
        "                (shape[3], shape[2], shape[0], shape[1]))\n",
        "            var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
        "            ptr += num_params\n",
        "            assign_ops.append(tf.assign(conv_var, var_weights))\n",
        "\n",
        "    return assign_ops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fnumqS7AzdY",
        "colab_type": "text"
      },
      "source": [
        "# 8. Running the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWoNzs2RAdDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_names = ['/content/gdrive/My Drive/data/yolo_v3/images/dog.jpg', '/content/gdrive/My Drive/data/yolo_v3/images/office.jpg']\n",
        "for img in img_names: display(Image.open(img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAt7gkR-RiUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = len(img_names)\n",
        "batch = load_images(img_names, model_size=_MODEL_SIZE)\n",
        "class_names = load_class_names('/content/gdrive/My Drive/data/yolo_v3/labels/coco.names')\n",
        "n_classes = len(class_names)\n",
        "max_output_size = 10\n",
        "iou_threshold = 0.5\n",
        "confidence_threshold = 0.5\n",
        "\n",
        "model = Yolo_v3(n_classes=n_classes, model_size=_MODEL_SIZE,\n",
        "                max_output_size=max_output_size,\n",
        "                iou_threshold=iou_threshold,\n",
        "                confidence_threshold=confidence_threshold)\n",
        "\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, 416, 416, 3])\n",
        "\n",
        "detections = model(inputs, training=False)\n",
        "\n",
        "model_vars = tf.global_variables(scope='yolo_v3_model')\n",
        "assign_ops = load_weights(model_vars, '/content/gdrive/My Drive/data/yolo_v3/yolov3.weights')\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(assign_ops)\n",
        "    detection_result = sess.run(detections, feed_dict={inputs: batch})\n",
        "    \n",
        "draw_boxes(img_names, detection_result, class_names, _MODEL_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMRCo6GOed8n",
        "colab_type": "text"
      },
      "source": [
        "# Yolo v3. 성능 특징.\n",
        "Yolo v3.는 작은 물체에 대한 성능은 높지만, Yolo v3는 큰 물체에 대한 인식은 떨어진 상태를 보여줍니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCr763OUGbWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}